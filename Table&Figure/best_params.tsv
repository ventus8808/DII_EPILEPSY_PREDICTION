Model	Parameters
LightGBM	n_estimators: 1000; max_depth: 20; learning_rate: 0.0063163702291310995; subsample: 0.592689818874548; colsample_bytree: 0.5035094509986247; reg_alpha: 3.3629726885973863; reg_lambda: 7.853598473816482; num_leaves: 548; min_child_samples: 57; min_child_weight: 8.486552576683524; class_weight: balanced; random_state: 42; boosting_type: gbdt; objective: binary; metric: binary_logloss; is_unbalance: true
RF	n_estimators: 494; max_depth: None; min_samples_split: 2; min_samples_leaf: 7; max_features: None
CatBoost	iterations: 538; learning_rate: 0.043139795651099266; depth: 9; l2_leaf_reg: 2.158927015190441; random_seed: 42; verbose: false; auto_class_weights: Balanced; cat_features: [3, 4, 5, 6, 7, 8, 9]
XGBoost	n_estimators: 200; max_depth: 10; learning_rate: 0.05547107987236009; subsample: 0.7672662615752976; colsample_bytree: 0.9940061502237982; reg_alpha: 1.70688313548634; reg_lambda: 0.6645430949475255; use_label_encoder: false; random_state: 42; eval_metric: logloss
FNN	units_1: 439; units_2: 185; dropout_1: 0.49015472745373256; dropout_2: 0.354572824524566; activation: relu; use_batch_norm: false; epochs: 100; optimizer: adamw; learning_rate: 0.0006825678586590903; batch_size: 128; early_stop_patience: 15
PSGD	loss: log_loss; penalty: l1; alpha: 1.094935335649899e-06; learning_rate: constant; class_weight: balanced; max_iter: 1939; random_state: 42; average: true; shuffle: false; fit_intercept: false; eta0: 0.00015549471110420937; early_stopping: false
Voting	xgb_weight: 2.913058688018509; lgbm_weight: 1.450053086864947; catboost_weight: 1.2164560403440476; rf_weight: 1.805324345417106; fnn_weight: 1.366946802760573; svm_weight: 0.21438198081235377; logistic_weight: 1.5274548983535923; voting_threshold: 0.603326154218688