{
    "units_1": 439,
    "units_2": 185,
    "dropout_1": 0.49015472745373256,
    "dropout_2": 0.354572824524566,
    "activation": "relu",
    "use_batch_norm": false,
    "epochs": 100,
    "optimizer": "adamw",
    "learning_rate": 0.0006825678586590903,
    "batch_size": 128,
    "early_stop_patience": 15
}