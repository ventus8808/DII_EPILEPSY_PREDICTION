2025-04-24 10:51:35,998 - INFO - Starting LightGBM model training
2025-04-24 10:51:35,998 - INFO - [并行调参说明] 本脚本支持Optuna多进程/多机并行调参，只需多开终端运行本脚本即可，Optuna会自动分配trial。
2025-04-24 10:51:36,042 - INFO - Running 10 trials for hyperparameter optimization
2025-04-24 10:51:36,043 - ERROR - Error during optimization: name 'train_fold' is not defined
2025-04-24 10:51:36,043 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 184, in optuna_objective
    metrics_fold = train_fold(fold, train_idx, val_idx, params)
NameError: name 'train_fold' is not defined

2025-04-24 10:51:36,044 - ERROR - Error during optimization: name 'train_fold' is not defined
2025-04-24 10:51:36,044 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 184, in optuna_objective
    metrics_fold = train_fold(fold, train_idx, val_idx, params)
NameError: name 'train_fold' is not defined

2025-04-24 10:51:36,045 - ERROR - Error during optimization: name 'train_fold' is not defined
2025-04-24 10:51:36,045 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 184, in optuna_objective
    metrics_fold = train_fold(fold, train_idx, val_idx, params)
NameError: name 'train_fold' is not defined

2025-04-24 10:51:36,046 - ERROR - Error during optimization: name 'train_fold' is not defined
2025-04-24 10:51:36,046 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 184, in optuna_objective
    metrics_fold = train_fold(fold, train_idx, val_idx, params)
NameError: name 'train_fold' is not defined

2025-04-24 10:51:36,047 - ERROR - Error during optimization: name 'train_fold' is not defined
2025-04-24 10:51:36,047 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 184, in optuna_objective
    metrics_fold = train_fold(fold, train_idx, val_idx, params)
NameError: name 'train_fold' is not defined

2025-04-24 10:51:36,048 - ERROR - Error during optimization: name 'train_fold' is not defined
2025-04-24 10:51:36,048 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 184, in optuna_objective
    metrics_fold = train_fold(fold, train_idx, val_idx, params)
NameError: name 'train_fold' is not defined

2025-04-24 10:51:36,049 - ERROR - Error during optimization: name 'train_fold' is not defined
2025-04-24 10:51:36,049 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 184, in optuna_objective
    metrics_fold = train_fold(fold, train_idx, val_idx, params)
NameError: name 'train_fold' is not defined

2025-04-24 10:51:36,050 - ERROR - Error during optimization: name 'train_fold' is not defined
2025-04-24 10:51:36,050 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 184, in optuna_objective
    metrics_fold = train_fold(fold, train_idx, val_idx, params)
NameError: name 'train_fold' is not defined

2025-04-24 10:51:36,051 - ERROR - Error during optimization: name 'train_fold' is not defined
2025-04-24 10:51:36,051 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 184, in optuna_objective
    metrics_fold = train_fold(fold, train_idx, val_idx, params)
NameError: name 'train_fold' is not defined

2025-04-24 10:51:36,052 - ERROR - Error during optimization: name 'train_fold' is not defined
2025-04-24 10:51:36,052 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 184, in optuna_objective
    metrics_fold = train_fold(fold, train_idx, val_idx, params)
NameError: name 'train_fold' is not defined

2025-04-24 10:51:36,053 - INFO - Best CV metrics: -inf
2025-04-24 10:51:36,053 - INFO - Final best parameters:
2025-04-24 10:51:36,053 - INFO - {'n_estimators': 200, 'max_depth': None, 'learning_rate': 0.25673295923989387, 'subsample': 0.6917143005172701, 'colsample_bytree': 0.4053913137500732, 'reg_alpha': 4.958276734975511, 'reg_lambda': 1.311395670705573, 'scale_pos_weight': 9.373836706331513, 'min_child_weight': 8.232078261961604, 'gamma': 3.0169739103474047}
2025-04-24 10:51:36,053 - INFO - Evaluating on held-out test set...
2025-04-24 10:52:57,597 - INFO - Starting LightGBM model training
2025-04-24 10:52:57,597 - INFO - [并行调参说明] 本脚本支持Optuna多进程/多机并行调参，只需多开终端运行本脚本即可，Optuna会自动分配trial。
2025-04-24 10:52:57,633 - INFO - Running 10 trials for hyperparameter optimization
2025-04-24 10:52:59,955 - ERROR - Error during optimization: name 'objective_function' is not defined
2025-04-24 10:52:59,956 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 214, in optuna_objective
    return objective_function(avg_metrics)
NameError: name 'objective_function' is not defined

2025-04-24 10:53:08,820 - ERROR - Error during optimization: name 'objective_function' is not defined
2025-04-24 10:53:08,820 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 214, in optuna_objective
    return objective_function(avg_metrics)
NameError: name 'objective_function' is not defined

2025-04-24 10:53:11,250 - ERROR - Error during optimization: name 'objective_function' is not defined
2025-04-24 10:53:11,250 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 214, in optuna_objective
    return objective_function(avg_metrics)
NameError: name 'objective_function' is not defined

2025-04-24 10:53:13,520 - ERROR - Error during optimization: name 'objective_function' is not defined
2025-04-24 10:53:13,520 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 214, in optuna_objective
    return objective_function(avg_metrics)
NameError: name 'objective_function' is not defined

2025-04-24 10:53:15,714 - ERROR - Error during optimization: name 'objective_function' is not defined
2025-04-24 10:53:15,714 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 214, in optuna_objective
    return objective_function(avg_metrics)
NameError: name 'objective_function' is not defined

2025-04-24 10:53:18,791 - ERROR - Error during optimization: name 'objective_function' is not defined
2025-04-24 10:53:18,791 - ERROR - Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 214, in optuna_objective
    return objective_function(avg_metrics)
NameError: name 'objective_function' is not defined

2025-04-24 11:02:31,841 - INFO - Starting LightGBM model training
2025-04-24 11:02:31,841 - INFO - [并行调参说明] 本脚本支持Optuna多进程/多机并行调参，只需多开终端运行本脚本即可，Optuna会自动分配trial。
2025-04-24 11:02:32,122 - INFO - Found existing LightGBM_best_params.json, evaluating initial score...
2025-04-24 11:02:35,890 - INFO - Initial best score from LightGBM_best_params.json: -inf
2025-04-24 11:02:35,890 - INFO - Initial best metrics: {'AUC': 0.9975489667055701, 'AUC-PR': 0.9982834175413929, 'Sensitivity': 0.9876448063593621, 'Specificity': 0.994326697608485, 'Precision': 0.9942901121995644, 'F1': 0.9909550554933139, 'ECE': 0.01042788732950165, 'MCE': 0.9999989989051699, 'Brier': 0.008022451256602909, 'LogLoss': 0.051454446451990876}
2025-04-24 11:03:49,041 - INFO - Starting LightGBM model training
2025-04-24 11:03:49,041 - INFO - [并行调参说明] 本脚本支持Optuna多进程/多机并行调参，只需多开终端运行本脚本即可，Optuna会自动分配trial。
2025-04-24 11:03:49,230 - INFO - Found existing LightGBM_best_params.json, evaluating initial score...
2025-04-24 11:03:52,708 - INFO - Initial best score from LightGBM_best_params.json: -inf
2025-04-24 11:03:52,708 - INFO - Initial best metrics: {'AUC': 0.9975489667055701, 'AUC-PR': 0.9982834175413929, 'Sensitivity': 0.9876448063593621, 'Specificity': 0.994326697608485, 'Precision': 0.9942901121995644, 'F1': 0.9909550554933139, 'ECE': 0.010427887329501647, 'MCE': 0.9999989989051699, 'Brier': 0.008022451256602909, 'LogLoss': 0.051454446451990675}
2025-04-24 11:03:52,747 - ERROR - [Trial 1][Fold 1/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,749 - ERROR - [Trial 1][Fold 2/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,751 - ERROR - [Trial 1][Fold 3/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,754 - ERROR - [Trial 1][Fold 4/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,756 - ERROR - [Trial 1][Fold 5/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,762 - INFO - [2025-04-24 11:03:52][Trial 1/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:03:52,777 - ERROR - [Trial 2][Fold 1/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,779 - ERROR - [Trial 2][Fold 2/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,782 - ERROR - [Trial 2][Fold 3/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,784 - ERROR - [Trial 2][Fold 4/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,786 - ERROR - [Trial 2][Fold 5/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,790 - INFO - [2025-04-24 11:03:52][Trial 2/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:03:52,805 - ERROR - [Trial 3][Fold 1/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,808 - ERROR - [Trial 3][Fold 2/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,810 - ERROR - [Trial 3][Fold 3/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,812 - ERROR - [Trial 3][Fold 4/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,814 - ERROR - [Trial 3][Fold 5/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,818 - INFO - [2025-04-24 11:03:52][Trial 3/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:03:52,835 - ERROR - [Trial 4][Fold 1/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,837 - ERROR - [Trial 4][Fold 2/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,839 - ERROR - [Trial 4][Fold 3/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,841 - ERROR - [Trial 4][Fold 4/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,843 - ERROR - [Trial 4][Fold 5/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,846 - INFO - [2025-04-24 11:03:52][Trial 4/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:03:52,862 - ERROR - [Trial 5][Fold 1/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,864 - ERROR - [Trial 5][Fold 2/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,867 - ERROR - [Trial 5][Fold 3/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,870 - ERROR - [Trial 5][Fold 4/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,872 - ERROR - [Trial 5][Fold 5/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,876 - INFO - [2025-04-24 11:03:52][Trial 5/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:03:52,892 - ERROR - [Trial 6][Fold 1/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,894 - ERROR - [Trial 6][Fold 2/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,896 - ERROR - [Trial 6][Fold 3/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,898 - ERROR - [Trial 6][Fold 4/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,900 - ERROR - [Trial 6][Fold 5/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,903 - INFO - [2025-04-24 11:03:52][Trial 6/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:03:52,918 - ERROR - [Trial 7][Fold 1/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,920 - ERROR - [Trial 7][Fold 2/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,922 - ERROR - [Trial 7][Fold 3/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,924 - ERROR - [Trial 7][Fold 4/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,927 - ERROR - [Trial 7][Fold 5/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,930 - INFO - [2025-04-24 11:03:52][Trial 7/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:03:52,945 - ERROR - [Trial 8][Fold 1/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,947 - ERROR - [Trial 8][Fold 2/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,949 - ERROR - [Trial 8][Fold 3/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,952 - ERROR - [Trial 8][Fold 4/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,954 - ERROR - [Trial 8][Fold 5/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,957 - INFO - [2025-04-24 11:03:52][Trial 8/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:03:52,971 - ERROR - [Trial 9][Fold 1/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,974 - ERROR - [Trial 9][Fold 2/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,976 - ERROR - [Trial 9][Fold 3/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,978 - ERROR - [Trial 9][Fold 4/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,980 - ERROR - [Trial 9][Fold 5/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:52,984 - INFO - [2025-04-24 11:03:52][Trial 9/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:03:52,999 - ERROR - [Trial 10][Fold 1/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:53,002 - ERROR - [Trial 10][Fold 2/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:53,004 - ERROR - [Trial 10][Fold 3/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:53,006 - ERROR - [Trial 10][Fold 4/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:53,008 - ERROR - [Trial 10][Fold 5/5] Exception: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 286, in train_fold
    X_res_fold, y_res_fold = smote_fold.fit_resample(Xy_tr.drop(['__label__'], axis=1), Xy_tr['__label__'])
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 202, in fit_resample
    return super().fit_resample(X, y, **params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/base.py", line 1389, in wrapper
    return fit_method(estimator, *args, **kwargs)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 99, in fit_resample
    X, y, binarize_y = self._check_X_y(X, y)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/imblearn/base.py", line 157, in _check_X_y
    X, y = validate_data(self, X=X, y=y, reset=True, accept_sparse=accept_sparse)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 2961, in validate_data
    X, y = check_X_y(X, y, **check_params)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1370, in check_X_y
    X = check_array(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 1107, in check_array
    _assert_all_finite(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 120, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 169, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input X contains NaN.
SMOTE does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values

2025-04-24 11:03:53,011 - INFO - [2025-04-24 11:03:53][Trial 10/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:03:53,011 - INFO - Training finished. Best score: -inf
2025-04-24 11:03:53,011 - INFO - Final best parameters:
2025-04-24 11:03:53,011 - INFO - n_estimators: 200
2025-04-24 11:03:53,011 - INFO - max_depth: None
2025-04-24 11:03:53,012 - INFO - learning_rate: 0.25673295923989387
2025-04-24 11:03:53,012 - INFO - subsample: 0.6917143005172701
2025-04-24 11:03:53,012 - INFO - colsample_bytree: 0.4053913137500732
2025-04-24 11:03:53,012 - INFO - reg_alpha: 4.958276734975511
2025-04-24 11:03:53,012 - INFO - reg_lambda: 1.311395670705573
2025-04-24 11:03:53,012 - INFO - scale_pos_weight: 9.373836706331513
2025-04-24 11:03:53,012 - INFO - min_child_weight: 8.232078261961604
2025-04-24 11:03:53,012 - INFO - gamma: 3.0169739103474047
2025-04-24 11:03:53,012 - INFO - random_state: 42
2025-04-24 11:03:53,012 - INFO - verbose: -1
2025-04-24 11:03:53,012 - INFO - class_weight: balanced
2025-04-24 11:03:53,012 - INFO - Final best metrics (CV mean):
2025-04-24 11:03:53,012 - INFO - AUC: 0.998
2025-04-24 11:03:53,012 - INFO - AUC-PR: 0.998
2025-04-24 11:03:53,012 - INFO - Sensitivity: 0.988
2025-04-24 11:03:53,012 - INFO - Specificity: 0.994
2025-04-24 11:03:53,012 - INFO - Precision: 0.994
2025-04-24 11:03:53,012 - INFO - F1: 0.991
2025-04-24 11:03:53,012 - INFO - ECE: 0.010
2025-04-24 11:03:53,012 - INFO - MCE: 1.000
2025-04-24 11:03:53,012 - INFO - Brier: 0.008
2025-04-24 11:03:53,012 - INFO - LogLoss: 0.051
2025-04-24 11:03:53,012 - INFO - Evaluating on held-out test set (never seen during training/tuning)...
2025-04-24 11:03:53,723 - INFO - Test set metrics (never seen during training/tuning):
2025-04-24 11:03:53,723 - INFO - AUC: 0.7220
2025-04-24 11:03:53,723 - INFO - AUC-PR: 0.3270
2025-04-24 11:03:53,723 - INFO - Sensitivity: 0.2903
2025-04-24 11:03:53,723 - INFO - Specificity: 0.9962
2025-04-24 11:03:53,723 - INFO - Precision: 0.5806
2025-04-24 11:03:53,723 - INFO - F1: 0.3871
2025-04-24 11:03:53,723 - INFO - ECE: 0.0205
2025-04-24 11:03:53,723 - INFO - MCE: 1.0000
2025-04-24 11:03:53,723 - INFO - Brier: 0.0155
2025-04-24 11:03:53,724 - INFO - LogLoss: 0.1335
2025-04-24 11:07:16,071 - INFO - Starting LightGBM model training
2025-04-24 11:07:16,071 - INFO - [并行调参说明] 本脚本支持Optuna多进程/多机并行调参，只需多开终端运行本脚本即可，Optuna会自动分配trial。
2025-04-24 11:08:24,228 - INFO - Starting LightGBM model training
2025-04-24 11:08:24,228 - INFO - [并行调参说明] 本脚本支持Optuna多进程/多机并行调参，只需多开终端运行本脚本即可，Optuna会自动分配trial。
2025-04-24 11:08:24,479 - INFO - Found existing LightGBM_best_params.json, evaluating initial score...
2025-04-24 11:08:29,753 - INFO - Initial best score from LightGBM_best_params.json: -inf
2025-04-24 11:08:29,753 - INFO - Initial best metrics: {'AUC': 0.9976121724185496, 'AUC-PR': 0.9983239590058315, 'Sensitivity': 0.9881491405182874, 'Specificity': 0.9959655651093252, 'Precision': 0.995936730198266, 'F1': 0.992026745752107, 'ECE': 0.009221727458501994, 'MCE': 0.999999779244918, 'Brier': 0.007185708012219574, 'LogLoss': 0.05078970086416339}
2025-04-24 11:08:29,847 - ERROR - [Trial 11][Fold 1/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:29,896 - ERROR - [Trial 11][Fold 2/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:29,943 - ERROR - [Trial 11][Fold 3/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:29,989 - ERROR - [Trial 11][Fold 4/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,005 - ERROR - [Trial 11][Fold 5/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,011 - INFO - [2025-04-24 11:08:30][Trial 1/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:08:30,083 - ERROR - [Trial 12][Fold 1/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,131 - ERROR - [Trial 12][Fold 2/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,178 - ERROR - [Trial 12][Fold 3/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,225 - ERROR - [Trial 12][Fold 4/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,243 - ERROR - [Trial 12][Fold 5/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,246 - INFO - [2025-04-24 11:08:30][Trial 2/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:08:30,322 - ERROR - [Trial 13][Fold 1/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,375 - ERROR - [Trial 13][Fold 2/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,429 - ERROR - [Trial 13][Fold 3/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,482 - ERROR - [Trial 13][Fold 4/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,505 - ERROR - [Trial 13][Fold 5/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,509 - INFO - [2025-04-24 11:08:30][Trial 3/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:08:30,580 - ERROR - [Trial 14][Fold 1/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,628 - ERROR - [Trial 14][Fold 2/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,676 - ERROR - [Trial 14][Fold 3/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,723 - ERROR - [Trial 14][Fold 4/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,742 - ERROR - [Trial 14][Fold 5/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,746 - INFO - [2025-04-24 11:08:30][Trial 4/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:08:30,818 - ERROR - [Trial 15][Fold 1/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,868 - ERROR - [Trial 15][Fold 2/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,918 - ERROR - [Trial 15][Fold 3/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,967 - ERROR - [Trial 15][Fold 4/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,986 - ERROR - [Trial 15][Fold 5/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:30,990 - INFO - [2025-04-24 11:08:30][Trial 5/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:08:31,058 - ERROR - [Trial 16][Fold 1/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,103 - ERROR - [Trial 16][Fold 2/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,148 - ERROR - [Trial 16][Fold 3/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,193 - ERROR - [Trial 16][Fold 4/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,209 - ERROR - [Trial 16][Fold 5/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,212 - INFO - [2025-04-24 11:08:31][Trial 6/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:08:31,287 - ERROR - [Trial 17][Fold 1/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,338 - ERROR - [Trial 17][Fold 2/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,389 - ERROR - [Trial 17][Fold 3/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,439 - ERROR - [Trial 17][Fold 4/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,460 - ERROR - [Trial 17][Fold 5/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,464 - INFO - [2025-04-24 11:08:31][Trial 7/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:08:31,535 - ERROR - [Trial 18][Fold 1/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,582 - ERROR - [Trial 18][Fold 2/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,628 - ERROR - [Trial 18][Fold 3/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,676 - ERROR - [Trial 18][Fold 4/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,693 - ERROR - [Trial 18][Fold 5/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,697 - INFO - [2025-04-24 11:08:31][Trial 8/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:08:31,774 - ERROR - [Trial 19][Fold 1/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,827 - ERROR - [Trial 19][Fold 2/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,879 - ERROR - [Trial 19][Fold 3/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,931 - ERROR - [Trial 19][Fold 4/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,954 - ERROR - [Trial 19][Fold 5/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:31,958 - INFO - [2025-04-24 11:08:31][Trial 9/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:08:32,028 - ERROR - [Trial 20][Fold 1/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:32,075 - ERROR - [Trial 20][Fold 2/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:32,121 - ERROR - [Trial 20][Fold 3/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:32,168 - ERROR - [Trial 20][Fold 4/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:32,185 - ERROR - [Trial 20][Fold 5/5] Exception: For early stopping, at least one dataset and eval metric is required for evaluation
Traceback (most recent call last):
  File "/Users/ventus/Repository/DII_EPILEPSY_PREDICTION/py_model/LightGBM_Train.py", line 321, in train_fold
    model.fit(X_tr_res, y_tr_res, sample_weight=w_tr_res)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1560, in fit
    super().fit(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/sklearn.py", line 1049, in fit
    self._Booster = train(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/engine.py", line 332, in train
    cb(
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 404, in __call__
    self._init(env)
  File "/opt/anaconda3/envs/ml/lib/python3.10/site-packages/lightgbm/callback.py", line 328, in _init
    raise ValueError("For early stopping, at least one dataset and eval metric is required for evaluation")
ValueError: For early stopping, at least one dataset and eval metric is required for evaluation

2025-04-24 11:08:32,189 - INFO - [2025-04-24 11:08:32][Trial 10/10] AUC-ROC=nan AUC-PR=nan Sens=nan Spec=nan Prec=nan Score=-inf
2025-04-24 11:08:32,189 - INFO - Training finished. Best score: -inf
2025-04-24 11:08:32,189 - INFO - Final best parameters:
2025-04-24 11:08:32,189 - INFO - n_estimators: 200
2025-04-24 11:08:32,189 - INFO - max_depth: None
2025-04-24 11:08:32,189 - INFO - learning_rate: 0.25673295923989387
2025-04-24 11:08:32,189 - INFO - subsample: 0.6917143005172701
2025-04-24 11:08:32,189 - INFO - colsample_bytree: 0.4053913137500732
2025-04-24 11:08:32,189 - INFO - reg_alpha: 4.958276734975511
2025-04-24 11:08:32,189 - INFO - reg_lambda: 1.311395670705573
2025-04-24 11:08:32,189 - INFO - scale_pos_weight: 9.373836706331513
2025-04-24 11:08:32,189 - INFO - min_child_weight: 8.232078261961604
2025-04-24 11:08:32,189 - INFO - gamma: 3.0169739103474047
2025-04-24 11:08:32,189 - INFO - random_state: 42
2025-04-24 11:08:32,189 - INFO - verbose: -1
2025-04-24 11:08:32,189 - INFO - class_weight: balanced
2025-04-24 11:08:32,189 - INFO - Final best metrics (CV mean):
2025-04-24 11:08:32,189 - INFO - AUC: 0.998
2025-04-24 11:08:32,189 - INFO - AUC-PR: 0.998
2025-04-24 11:08:32,189 - INFO - Sensitivity: 0.988
2025-04-24 11:08:32,189 - INFO - Specificity: 0.996
2025-04-24 11:08:32,189 - INFO - Precision: 0.996
2025-04-24 11:08:32,189 - INFO - F1: 0.992
2025-04-24 11:08:32,189 - INFO - ECE: 0.009
2025-04-24 11:08:32,189 - INFO - MCE: 1.000
2025-04-24 11:08:32,189 - INFO - Brier: 0.007
2025-04-24 11:08:32,189 - INFO - LogLoss: 0.051
2025-04-24 11:08:32,189 - INFO - Evaluating on held-out test set (never seen during training/tuning)...
2025-04-24 11:08:33,265 - INFO - Test set metrics (never seen during training/tuning):
2025-04-24 11:08:33,265 - INFO - AUC: 0.7726
2025-04-24 11:08:33,265 - INFO - AUC-PR: 0.3458
2025-04-24 11:08:33,265 - INFO - Sensitivity: 0.2903
2025-04-24 11:08:33,265 - INFO - Specificity: 0.9959
2025-04-24 11:08:33,265 - INFO - Precision: 0.5625
2025-04-24 11:08:33,265 - INFO - F1: 0.3830
2025-04-24 11:08:33,265 - INFO - ECE: 0.0199
2025-04-24 11:08:33,265 - INFO - MCE: 1.0000
2025-04-24 11:08:33,265 - INFO - Brier: 0.0152
2025-04-24 11:08:33,265 - INFO - LogLoss: 0.1217
2025-04-24 11:10:03,841 - INFO - Starting LightGBM model training
2025-04-24 11:10:03,841 - INFO - [并行调参说明] 本脚本支持Optuna多进程/多机并行调参，只需多开终端运行本脚本即可，Optuna会自动分配trial。
2025-04-24 11:10:04,126 - INFO - Found existing LightGBM_best_params.json, evaluating initial score...
2025-04-24 11:10:09,270 - INFO - Initial best score from LightGBM_best_params.json: -inf
2025-04-24 11:10:09,270 - INFO - Initial best metrics: {'AUC': 0.9976121724185496, 'AUC-PR': 0.9983239590058315, 'Sensitivity': 0.9881491405182874, 'Specificity': 0.9959655651093252, 'Precision': 0.995936730198266, 'F1': 0.992026745752107, 'ECE': 0.009221727458501994, 'MCE': 0.999999779244918, 'Brier': 0.007185708012219574, 'LogLoss': 0.05078970086416339}
2025-04-24 11:10:11,328 - INFO - [Trial 21] 5-fold mean metrics: {'AUC': 0.997, 'AUC-PR': 0.998, 'Sensitivity': 0.983, 'Specificity': 0.996, 'Precision': 0.996, 'F1': 0.99, 'ECE': 0.016, 'MCE': 1.0, 'Brier': 0.009, 'LogLoss': 0.04}
2025-04-24 11:10:11,342 - INFO - [2025-04-24 11:10:11][Trial 1/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.983 Spec=0.996 Prec=0.996 Score=-inf
2025-04-24 11:10:12,798 - INFO - [Trial 22] 5-fold mean metrics: {'AUC': 0.997, 'AUC-PR': 0.998, 'Sensitivity': 0.98, 'Specificity': 0.996, 'Precision': 0.996, 'F1': 0.988, 'ECE': 0.021, 'MCE': 0.999, 'Brier': 0.01, 'LogLoss': 0.043}
2025-04-24 11:10:12,809 - INFO - [2025-04-24 11:10:12][Trial 2/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.980 Spec=0.996 Prec=0.996 Score=-inf
2025-04-24 11:10:14,202 - INFO - [Trial 23] 5-fold mean metrics: {'AUC': 0.997, 'AUC-PR': 0.998, 'Sensitivity': 0.98, 'Specificity': 0.996, 'Precision': 0.996, 'F1': 0.988, 'ECE': 0.021, 'MCE': 0.999, 'Brier': 0.01, 'LogLoss': 0.043}
2025-04-24 11:10:14,213 - INFO - [2025-04-24 11:10:14][Trial 3/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.980 Spec=0.996 Prec=0.996 Score=-inf
2025-04-24 11:10:16,159 - INFO - [Trial 24] 5-fold mean metrics: {'AUC': 0.998, 'AUC-PR': 0.998, 'Sensitivity': 0.982, 'Specificity': 0.996, 'Precision': 0.996, 'F1': 0.989, 'ECE': 0.017, 'MCE': 1.0, 'Brier': 0.009, 'LogLoss': 0.04}
2025-04-24 11:10:16,170 - INFO - [2025-04-24 11:10:16][Trial 4/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.982 Spec=0.996 Prec=0.996 Score=-inf
2025-04-24 11:10:20,326 - INFO - [Trial 25] 5-fold mean metrics: {'AUC': 0.998, 'AUC-PR': 0.998, 'Sensitivity': 0.988, 'Specificity': 0.998, 'Precision': 0.998, 'F1': 0.993, 'ECE': 0.01, 'MCE': 1.0, 'Brier': 0.007, 'LogLoss': 0.039}
2025-04-24 11:10:20,337 - INFO - [2025-04-24 11:10:20][Trial 5/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.988 Spec=0.998 Prec=0.998 Score=-inf
2025-04-24 11:10:21,549 - INFO - [Trial 26] 5-fold mean metrics: {'AUC': 0.997, 'AUC-PR': 0.998, 'Sensitivity': 0.979, 'Specificity': 0.997, 'Precision': 0.997, 'F1': 0.988, 'ECE': 0.023, 'MCE': 0.999, 'Brier': 0.01, 'LogLoss': 0.044}
2025-04-24 11:10:21,561 - INFO - [2025-04-24 11:10:21][Trial 6/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.979 Spec=0.997 Prec=0.997 Score=-inf
2025-04-24 11:10:24,783 - INFO - [Trial 27] 5-fold mean metrics: {'AUC': 0.998, 'AUC-PR': 0.998, 'Sensitivity': 0.987, 'Specificity': 0.997, 'Precision': 0.997, 'F1': 0.992, 'ECE': 0.011, 'MCE': 1.0, 'Brier': 0.007, 'LogLoss': 0.04}
2025-04-24 11:10:24,794 - INFO - [2025-04-24 11:10:24][Trial 7/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.987 Spec=0.997 Prec=0.997 Score=-inf
2025-04-24 11:10:27,830 - INFO - [Trial 28] 5-fold mean metrics: {'AUC': 0.998, 'AUC-PR': 0.998, 'Sensitivity': 0.986, 'Specificity': 0.998, 'Precision': 0.998, 'F1': 0.992, 'ECE': 0.013, 'MCE': 1.0, 'Brier': 0.008, 'LogLoss': 0.039}
2025-04-24 11:10:27,840 - INFO - [2025-04-24 11:10:27][Trial 8/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.986 Spec=0.998 Prec=0.998 Score=-inf
2025-04-24 11:10:36,801 - INFO - [Trial 29] 5-fold mean metrics: {'AUC': 0.998, 'AUC-PR': 0.999, 'Sensitivity': 0.988, 'Specificity': 0.998, 'Precision': 0.998, 'F1': 0.993, 'ECE': 0.007, 'MCE': 1.0, 'Brier': 0.006, 'LogLoss': 0.056}
2025-04-24 11:10:36,813 - INFO - [2025-04-24 11:10:36][Trial 9/10] AUC-ROC=nan AUC-PR=0.999 Sens=0.988 Spec=0.998 Prec=0.998 Score=-inf
2025-04-24 11:10:38,993 - INFO - [Trial 30] 5-fold mean metrics: {'AUC': 0.997, 'AUC-PR': 0.998, 'Sensitivity': 0.983, 'Specificity': 0.996, 'Precision': 0.996, 'F1': 0.989, 'ECE': 0.016, 'MCE': 1.0, 'Brier': 0.009, 'LogLoss': 0.042}
2025-04-24 11:10:39,004 - INFO - [2025-04-24 11:10:39][Trial 10/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.983 Spec=0.996 Prec=0.996 Score=-inf
2025-04-24 11:10:39,004 - INFO - Training finished. Best score: -inf
2025-04-24 11:10:39,004 - INFO - Final best parameters:
2025-04-24 11:10:39,004 - INFO - n_estimators: 200
2025-04-24 11:10:39,004 - INFO - max_depth: None
2025-04-24 11:10:39,004 - INFO - learning_rate: 0.25673295923989387
2025-04-24 11:10:39,004 - INFO - subsample: 0.6917143005172701
2025-04-24 11:10:39,004 - INFO - colsample_bytree: 0.4053913137500732
2025-04-24 11:10:39,004 - INFO - reg_alpha: 4.958276734975511
2025-04-24 11:10:39,004 - INFO - reg_lambda: 1.311395670705573
2025-04-24 11:10:39,004 - INFO - scale_pos_weight: 9.373836706331513
2025-04-24 11:10:39,005 - INFO - min_child_weight: 8.232078261961604
2025-04-24 11:10:39,005 - INFO - gamma: 3.0169739103474047
2025-04-24 11:10:39,005 - INFO - random_state: 42
2025-04-24 11:10:39,005 - INFO - verbose: -1
2025-04-24 11:10:39,005 - INFO - class_weight: balanced
2025-04-24 11:10:39,005 - INFO - Final best metrics (CV mean):
2025-04-24 11:10:39,005 - INFO - AUC: 0.998
2025-04-24 11:10:39,005 - INFO - AUC-PR: 0.998
2025-04-24 11:10:39,005 - INFO - Sensitivity: 0.988
2025-04-24 11:10:39,005 - INFO - Specificity: 0.996
2025-04-24 11:10:39,005 - INFO - Precision: 0.996
2025-04-24 11:10:39,005 - INFO - F1: 0.992
2025-04-24 11:10:39,005 - INFO - ECE: 0.009
2025-04-24 11:10:39,005 - INFO - MCE: 1.000
2025-04-24 11:10:39,005 - INFO - Brier: 0.007
2025-04-24 11:10:39,005 - INFO - LogLoss: 0.051
2025-04-24 11:10:39,005 - INFO - Evaluating on held-out test set (never seen during training/tuning)...
2025-04-24 11:10:40,056 - INFO - Test set metrics (never seen during training/tuning):
2025-04-24 11:10:40,056 - INFO - AUC: 0.7726
2025-04-24 11:10:40,056 - INFO - AUC-PR: 0.3458
2025-04-24 11:10:40,056 - INFO - Sensitivity: 0.2903
2025-04-24 11:10:40,056 - INFO - Specificity: 0.9959
2025-04-24 11:10:40,056 - INFO - Precision: 0.5625
2025-04-24 11:10:40,056 - INFO - F1: 0.3830
2025-04-24 11:10:40,056 - INFO - ECE: 0.0199
2025-04-24 11:10:40,056 - INFO - MCE: 1.0000
2025-04-24 11:10:40,056 - INFO - Brier: 0.0152
2025-04-24 11:10:40,056 - INFO - LogLoss: 0.1217
2025-04-24 11:12:13,693 - INFO - Starting LightGBM model training
2025-04-24 11:12:13,693 - INFO - [并行调参说明] 本脚本支持Optuna多进程/多机并行调参，只需多开终端运行本脚本即可，Optuna会自动分配trial。
2025-04-24 11:12:13,943 - INFO - Found existing LightGBM_best_params.json, evaluating initial score...
2025-04-24 11:12:19,175 - INFO - Initial best score from LightGBM_best_params.json: -inf
2025-04-24 11:12:19,175 - INFO - Initial best metrics: {'AUC': 0.9976121724185496, 'AUC-PR': 0.9983239590058315, 'Sensitivity': 0.9881491405182874, 'Specificity': 0.9959655651093252, 'Precision': 0.995936730198266, 'F1': 0.992026745752107, 'ECE': 0.009221727458501994, 'MCE': 0.999999779244918, 'Brier': 0.007185708012219574, 'LogLoss': 0.05078970086416339}
2025-04-24 11:12:20,691 - INFO - [Trial 31] 5-fold mean metrics: {'AUC': 0.997, 'AUC-PR': 0.998, 'Sensitivity': 0.99, 'Specificity': 0.951, 'Precision': 0.953, 'F1': 0.971, 'ECE': 0.053, 'MCE': 0.994, 'Brier': 0.022, 'LogLoss': 0.077}
2025-04-24 11:12:20,704 - INFO - [2025-04-24 11:12:20][Trial 1/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.990 Spec=0.951 Prec=0.953 Score=-inf
2025-04-24 11:12:22,276 - INFO - [Trial 32] 5-fold mean metrics: {'AUC': 0.997, 'AUC-PR': 0.998, 'Sensitivity': 0.988, 'Specificity': 0.962, 'Precision': 0.963, 'F1': 0.976, 'ECE': 0.048, 'MCE': 0.994, 'Brier': 0.019, 'LogLoss': 0.069}
2025-04-24 11:12:22,288 - INFO - [2025-04-24 11:12:22][Trial 2/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.988 Spec=0.962 Prec=0.963 Score=-inf
2025-04-24 11:12:24,434 - INFO - [Trial 33] 5-fold mean metrics: {'AUC': 0.998, 'AUC-PR': 0.998, 'Sensitivity': 0.988, 'Specificity': 0.972, 'Precision': 0.972, 'F1': 0.98, 'ECE': 0.037, 'MCE': 0.997, 'Brier': 0.015, 'LogLoss': 0.057}
2025-04-24 11:12:24,446 - INFO - [2025-04-24 11:12:24][Trial 3/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.988 Spec=0.972 Prec=0.972 Score=-inf
2025-04-24 11:12:29,735 - INFO - [Trial 34] 5-fold mean metrics: {'AUC': 0.998, 'AUC-PR': 0.998, 'Sensitivity': 0.99, 'Specificity': 0.987, 'Precision': 0.987, 'F1': 0.989, 'ECE': 0.019, 'MCE': 1.0, 'Brier': 0.01, 'LogLoss': 0.04}
2025-04-24 11:12:29,748 - INFO - [2025-04-24 11:12:29][Trial 4/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.990 Spec=0.987 Prec=0.987 Score=-inf
2025-04-24 11:12:31,405 - INFO - [Trial 35] 5-fold mean metrics: {'AUC': 0.997, 'AUC-PR': 0.998, 'Sensitivity': 0.989, 'Specificity': 0.961, 'Precision': 0.962, 'F1': 0.976, 'ECE': 0.048, 'MCE': 0.993, 'Brier': 0.019, 'LogLoss': 0.07}
2025-04-24 11:12:31,417 - INFO - [2025-04-24 11:12:31][Trial 5/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.989 Spec=0.961 Prec=0.962 Score=-inf
2025-04-24 11:12:34,022 - INFO - [Trial 36] 5-fold mean metrics: {'AUC': 0.998, 'AUC-PR': 0.998, 'Sensitivity': 0.989, 'Specificity': 0.975, 'Precision': 0.975, 'F1': 0.982, 'ECE': 0.034, 'MCE': 0.999, 'Brier': 0.014, 'LogLoss': 0.054}
2025-04-24 11:12:34,035 - INFO - [2025-04-24 11:12:34][Trial 6/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.989 Spec=0.975 Prec=0.975 Score=-inf
2025-04-24 11:12:37,666 - INFO - [Trial 37] 5-fold mean metrics: {'AUC': 0.998, 'AUC-PR': 0.998, 'Sensitivity': 0.989, 'Specificity': 0.983, 'Precision': 0.983, 'F1': 0.986, 'ECE': 0.025, 'MCE': 0.999, 'Brier': 0.011, 'LogLoss': 0.044}
2025-04-24 11:12:37,678 - INFO - [2025-04-24 11:12:37][Trial 7/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.989 Spec=0.983 Prec=0.983 Score=-inf
2025-04-24 11:12:42,728 - INFO - [Trial 38] 5-fold mean metrics: {'AUC': 0.998, 'AUC-PR': 0.999, 'Sensitivity': 0.99, 'Specificity': 0.986, 'Precision': 0.986, 'F1': 0.988, 'ECE': 0.02, 'MCE': 1.0, 'Brier': 0.01, 'LogLoss': 0.04}
2025-04-24 11:12:42,740 - INFO - [2025-04-24 11:12:42][Trial 8/10] AUC-ROC=nan AUC-PR=0.999 Sens=0.990 Spec=0.986 Prec=0.986 Score=-inf
2025-04-24 11:12:45,146 - INFO - [Trial 39] 5-fold mean metrics: {'AUC': 0.998, 'AUC-PR': 0.998, 'Sensitivity': 0.988, 'Specificity': 0.975, 'Precision': 0.976, 'F1': 0.982, 'ECE': 0.035, 'MCE': 0.997, 'Brier': 0.015, 'LogLoss': 0.055}
2025-04-24 11:12:45,158 - INFO - [2025-04-24 11:12:45][Trial 9/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.988 Spec=0.975 Prec=0.976 Score=-inf
2025-04-24 11:12:46,694 - INFO - [Trial 40] 5-fold mean metrics: {'AUC': 0.997, 'AUC-PR': 0.998, 'Sensitivity': 0.989, 'Specificity': 0.96, 'Precision': 0.961, 'F1': 0.975, 'ECE': 0.048, 'MCE': 0.991, 'Brier': 0.019, 'LogLoss': 0.071}
2025-04-24 11:12:46,706 - INFO - [2025-04-24 11:12:46][Trial 10/10] AUC-ROC=nan AUC-PR=0.998 Sens=0.989 Spec=0.960 Prec=0.961 Score=-inf
2025-04-24 11:12:46,707 - INFO - Training finished. Best score: -inf
2025-04-24 11:12:46,707 - INFO - Final best parameters:
2025-04-24 11:12:46,707 - INFO - n_estimators: 200
2025-04-24 11:12:46,707 - INFO - max_depth: None
2025-04-24 11:12:46,707 - INFO - learning_rate: 0.25673295923989387
2025-04-24 11:12:46,707 - INFO - subsample: 0.6917143005172701
2025-04-24 11:12:46,707 - INFO - colsample_bytree: 0.4053913137500732
2025-04-24 11:12:46,707 - INFO - reg_alpha: 4.958276734975511
2025-04-24 11:12:46,707 - INFO - reg_lambda: 1.311395670705573
2025-04-24 11:12:46,707 - INFO - scale_pos_weight: 9.373836706331513
2025-04-24 11:12:46,707 - INFO - min_child_weight: 8.232078261961604
2025-04-24 11:12:46,707 - INFO - gamma: 3.0169739103474047
2025-04-24 11:12:46,707 - INFO - random_state: 42
2025-04-24 11:12:46,707 - INFO - verbose: -1
2025-04-24 11:12:46,707 - INFO - class_weight: balanced
2025-04-24 11:12:46,707 - INFO - Final best metrics (CV mean):
2025-04-24 11:12:46,707 - INFO - AUC: 0.998
2025-04-24 11:12:46,707 - INFO - AUC-PR: 0.998
2025-04-24 11:12:46,707 - INFO - Sensitivity: 0.988
2025-04-24 11:12:46,707 - INFO - Specificity: 0.996
2025-04-24 11:12:46,707 - INFO - Precision: 0.996
2025-04-24 11:12:46,707 - INFO - F1: 0.992
2025-04-24 11:12:46,707 - INFO - ECE: 0.009
2025-04-24 11:12:46,707 - INFO - MCE: 1.000
2025-04-24 11:12:46,707 - INFO - Brier: 0.007
2025-04-24 11:12:46,707 - INFO - LogLoss: 0.051
2025-04-24 11:12:46,707 - INFO - Evaluating on held-out test set (never seen during training/tuning)...
2025-04-24 11:12:47,775 - INFO - Test set metrics (never seen during training/tuning):
2025-04-24 11:12:47,775 - INFO - AUC: 0.7726
2025-04-24 11:12:47,775 - INFO - AUC-PR: 0.3458
2025-04-24 11:12:47,775 - INFO - Sensitivity: 0.2903
2025-04-24 11:12:47,775 - INFO - Specificity: 0.9959
2025-04-24 11:12:47,775 - INFO - Precision: 0.5625
2025-04-24 11:12:47,775 - INFO - F1: 0.3830
2025-04-24 11:12:47,775 - INFO - ECE: 0.0199
2025-04-24 11:12:47,775 - INFO - MCE: 1.0000
2025-04-24 11:12:47,775 - INFO - Brier: 0.0152
2025-04-24 11:12:47,775 - INFO - LogLoss: 0.1217
